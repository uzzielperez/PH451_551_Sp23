{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UAPH451551/PH451_551_Sp23/blob/main/Resources/Reading_Documentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Code Documentation\n",
        "\n",
        "Before reading this, please review PythonRefreshers_1 and PythonRefreshers_2"
      ],
      "metadata": {
        "id": "xFE19A0Ua49I"
      },
      "id": "xFE19A0Ua49I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e018aed",
      "metadata": {
        "id": "5e018aed"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import curve_fit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we'll be exploring **how to read code documentation** for common libraries.<br> \n",
        "Consider some data that looks like the following: **x is some random value 100**.<br> \n",
        "And **y = e^(x * A) + B** where A is some random value between 0 and 10 and B is<br>\n",
        "some random value between 0 and 50. If we know that our relationship between y<br>\n",
        "and x generally fits some exponential curved function then we might use a<br>\n",
        "pre-existing **curve-fitting function** from a common python library to help **solve**<br>\n",
        "**for the exact value of A and B**. The question is then, how do we interpret the <br>\n",
        "code documentation for such a library to understand how to use such a function.\n",
        "\n",
        "First, let's generate some data:"
      ],
      "metadata": {
        "id": "1kUlaYzfCbIt"
      },
      "id": "1kUlaYzfCbIt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d0aea3",
      "metadata": {
        "id": "68d0aea3"
      },
      "outputs": [],
      "source": [
        "\n",
        "x = np.arange(0, 1, .01) # x = 0.0,0.01....99,1.0\n",
        "A = np.random.uniform(low=0, high=10, size=1) # A is a random float from 0 to 10\n",
        "B = np.random.uniform(low=0, high=50, size=1) # B is a random float from 0 to 50\n",
        "y = np.exp(x * A) + B # y = e^(x * A) + B"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon googling or checking stack overflow, we might find that the **scipy** library<br> \n",
        "contains at least one tool for such a task: **curve_fit**. Let's look at the<br>\n",
        "documentation for curve_fit to see how it works.\n",
        "\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\n",
        "\n",
        "scipy.optimize.curve_fit\n",
        "\n",
        "scipy.optimize.curve_fit(f, xdata, ydata, p0=None, sigma=None,\n",
        "                         absolute_sigma=False, \n",
        "                         check_finite=True, bounds=(- inf, inf), \n",
        "                         method=None, jac=None,\n",
        "                         *, full_output=False, **kwargs)[[source]](https://github.com/scipy/scipy/blob/v1.9.3/scipy/optimize/_minpack_py.py#L533-L887)\n",
        "                         \n",
        "\n",
        "    Use non-linear least squares to fit a function, f, to data.\n",
        "\n",
        "    Assumes ydata = f(xdata, *params) + eps.\n",
        "\n",
        "**Parameters**\n",
        "\n",
        "     f: callable\n",
        "         The model function, f(x, …). It must take the independent variable as\n",
        "         the first argument and the parameters to fit as separate remaining\n",
        "         arguments.\n",
        "\n",
        "     x: dataarray_like or object\n",
        "         The independent variable where the data is measured. Should usually be\n",
        "         an M-length sequence or an (k,M)-shaped array for functions with k \n",
        "         predictors, but can actually \n",
        "         be any object.\n",
        "\n",
        "     y: dataarray_like\n",
        "         The dependent data, a length M array - nominally f(xdata, ...).\n",
        "\n",
        "     p0: array_like, optional\n",
        "         Initial guess for the parameters (length N). If None, then the initial \n",
        "         values will all be 1 (if the number of parameters for the function can \n",
        "         be determined using introspection, otherwise a ValueError is raised).\n",
        "\n",
        "     sigma: None or M-length sequence or MxM array, optional\n",
        "         Determines the uncertainty in ydata. If we define residuals as \n",
        "         r = ydata - f(xdata, *popt), then the interpretation of sigma depends \n",
        "         on its number \n",
        "         of dimensions:\n",
        "             -A 1-D sigma should contain values of standard deviations of \n",
        "             errors in ydata. \n",
        "              In this case, the optimized function is chisq = sum((r / sigma) \n",
        "              ** 2).\n",
        "             -A 2-D sigma should contain the covariance matrix of errors in \n",
        "             ydata. \n",
        "              In this case, the optimized function is chisq = r.T @ inv(sigma) \n",
        "              @ r.\n",
        "             None (default) is equivalent of 1-D sigma filled with ones.\n",
        "\n",
        "     absolute_sigma: bool, optional\n",
        "         If True, sigma is used in an absolute sense and the estimated \n",
        "         parameter covariance\n",
        "         pcov reflects these absolute values.\n",
        "         If False (default), only the relative magnitudes of the sigma values \n",
        "         matter. The returned parameter covariance matrix pcov is based on \n",
        "         scaling sigma by a constant factor. This constant is set by demanding \n",
        "         that the reduced chisq for the optimal parameters popt when using the \n",
        "         scaled sigma equals unity. In other words, sigma is scaled to match \n",
        "         the sample variance of the residuals after the fit. Default is False. \n",
        "         Mathematically, pcov(absolute_sigma=False) = \n",
        "         pcov(absolute_sigma=True) * chisq(popt)/(M-N)\n",
        "\n",
        "     check_finite: bool, optional\n",
        "         If True, check that the input arrays do not contain nans of infs, and \n",
        "         raise a ValueError if they do. Setting this parameter to False may \n",
        "         silently produce nonsensical results if the input arrays do contain \n",
        "         nans. Default is True.\n",
        "\n",
        "     bounds: 2-tuple of array_like, optional\n",
        "         Lower and upper bounds on parameters. Defaults to no bounds. Each \n",
        "         element of the tuple must be either an array with the length equal to \n",
        "         the number of parameters, or a scalar (in which case the bound is \n",
        "         taken to be the same for all parameters). Use np.inf with an \n",
        "         appropriate sign to disable bounds on all or some parameters.\n",
        "\n",
        "     method: {‘lm’, ‘trf’, ‘dogbox’}, optional\n",
        "         Method to use for optimization. See least_squares for more details. \n",
        "         Default is ‘lm’ for \n",
        "         unconstrained problems and ‘trf’ if bounds are provided. The method \n",
        "         ‘lm’ won’t work when \n",
        "         the number of observations is less than the number of variables, use \n",
        "         ‘trf’ or ‘dogbox’ \n",
        "         in this case.\n",
        "\n",
        "     jac: callable, string or None, optional\n",
        "         Function with signature jac(x, ...) which computes the Jacobian matrix \n",
        "         of the model function with respect to parameters as a dense array_like \n",
        "         structure. It will be scaled according to provided sigma. If None \n",
        "         (default), the Jacobian will be estimated numerically. String keywords \n",
        "         for ‘trf’ and ‘dogbox’ methods can be used to select a finite \n",
        "         difference scheme, see least_squares.\n",
        "\n",
        "     full_output: boolean, optional\n",
        "         If True, this function returns additioal information: infodict, mesg, \n",
        "         and ier.\n",
        "\n",
        "     **kwargs\n",
        "         Keyword arguments passed to leastsq for method='lm' or least_squares \n",
        "         otherwise.\n",
        "\n",
        "**Returns**\n",
        " \n",
        "     popt: array\n",
        "         Optimal values for the parameters so that the sum of the squared \n",
        "         residuals of \n",
        "         f(xdata, *popt) - ydata is minimized.\n",
        "\n",
        "     pcov: 2-D array\n",
        "         The estimated covariance of popt. The diagonals provide the variance \n",
        "         of the parameter estimate. To compute one standard deviation errors on \n",
        "         the parameters use perr = np.sqrt(np.diag(pcov)). How the sigma \n",
        "         parameter affects the estimated covariance depends on absolute_sigma \n",
        "         argument, as described above. If the Jacobian matrix at the solution \n",
        "         doesn’t have a full rank, then ‘lm’ method returns a matrix filled \n",
        "         with np.inf, on the other hand ‘trf’ and ‘dogbox’ methods use \n",
        "         Moore-Penrose pseudoinverse to compute the covariance matrix.\n",
        "\n",
        "     infodict: dict (returned only if full_output is True)\n",
        "         a dictionary of optional outputs with the keys:\n",
        "\n",
        "         nfev\n",
        "         The number of function calls. Methods ‘trf’ and ‘dogbox’ do not count \n",
        "         function calls for numerical Jacobian approximation, as opposed to \n",
        "         ‘lm’ method.\n",
        "\n",
        "         fvec\n",
        "         The function values evaluated at the solution.\n",
        "\n",
        "         fjac\n",
        "         A permutation of the R matrix of a QR factorization of the final \n",
        "         approximate Jacobian matrix, stored column wise. Together with ipvt, \n",
        "         the covariance of the estimate can be approximated. Method ‘lm’ only \n",
        "         provides this information.\n",
        "\n",
        "         ipvt\n",
        "         An integer array of length N which defines a permutation matrix, p, \n",
        "         such that fjac*p = q*r, where r is upper triangular with diagonal \n",
        "         elements of nonincreasing magnitude. Column j of p is column ipvt(j) \n",
        "         of the identity matrix. Method ‘lm’ only provides this information.\n",
        "\n",
        "         qtf\n",
        "         The vector (transpose(q) * fvec). Method ‘lm’ only provides this \n",
        "         information.\n",
        "\n",
        "     mesgstr: (returned only if full_output is True)\n",
        "         A string message giving information about the solution.\n",
        "\n",
        "     ierint: (returnned only if full_output is True)\n",
        "         An integer flag. If it is equal to 1, 2, 3 or 4, the solution was \n",
        "         found. Otherwise, the solution was not found. In either case, the \n",
        "         optional output variable mesg gives more information.\n",
        "\n",
        "**Raises**\n",
        "\n",
        "     ValueError\n",
        "     if either ydata or xdata contain NaNs, or if incompatible options are used.\n",
        "\n",
        "     RuntimeError\n",
        "     if the least-squares minimization fails.\n",
        "\n",
        "     OptimizeWarning\n",
        "     if covariance of the parameters can not be estimated."
      ],
      "metadata": {
        "id": "LDzdO4qTCzJD"
      },
      "id": "LDzdO4qTCzJD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's *a lot* of documentation to read through but there are some shortcuts<br> \n",
        "that we can use to **narrow down what is it that we actually need** from all of<br> that. First, let's **separate the parameters of the function** that we'll<br> **definitely need** from the ones that are either **optional or have default settings**.\n",
        "\n",
        "**Required:**\n",
        "\n",
        "     f: callable\n",
        "         The model function, f(x, …). It must take the independent variable as\n",
        "         the first argument and the parameters to fit as separate remaining \n",
        "         arguments.\n",
        "\n",
        "     x: dataarray_like or object\n",
        "         The independent variable where the data is measured. Should usually be \n",
        "         an M-length sequence or an (k,M)-shaped array for functions with k \n",
        "         predictors, but can actually be any object.\n",
        "\n",
        "     y: dataarray_like\n",
        "         The dependent data, a length M array - nominally f(xdata, ...).\n",
        "\n",
        "\n",
        "It turns out **only 3 things are actually required** for the function to operate.<br> \n",
        "We need some **input data (x)**, some **output data (y)** and some kind of a callable<br> \n",
        "python **function which will convert x values to their corresponding y values**.<br> \n",
        "Furthermore, earlier in the documentation it states the following: Assumes<br> **ydata = f(xdata, *params) + eps**. Given that, we know that our function should<br> \n",
        "be defined such that **if we call our function on our x** values and the parameters<br> \n",
        "we want to fit, **we'll get our y values**.\n",
        "\n",
        "Given that information, we know what our general form of f(x) should be:"
      ],
      "metadata": {
        "id": "pbxtKKr4GvuE"
      },
      "id": "pbxtKKr4GvuE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28bac578",
      "metadata": {
        "id": "28bac578"
      },
      "outputs": [],
      "source": [
        "\n",
        "def exponential_function(x, a, b):\n",
        "    y = np.exp(x * a) + b\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So now we have appropriate inputs to our fitting function. Let's now do the<br> same simplification of our outputs. Let's ignore anything that's optional.<br> Reading the documentation we can see that **many of the things that get returned<br> \n",
        "have the added description \"returned only if full_output is True\"**. And the<br> **default setting for full_output is full_output=False**. That means the function<br> \n",
        "will most likely give us the main information we're after even if<br> full_output=False and that **many of the returned variables are optional**<br> additional information. Let's assume for this use case that **we'll leave**<br> **full_output=False**. That leaves us with only two core returned values.\n",
        "\n",
        "\n",
        "     popt: array\n",
        "         Optimal values for the parameters so that the sum of the squared \n",
        "         residuals of f(xdata, *popt) - ydata is minimized.\n",
        "\n",
        "     pcov: 2-D array\n",
        "         The estimated covariance of popt. The diagonals provide the variance \n",
        "         of the parameter estimate. To compute one standard deviation errors on \n",
        "         the parameters use perr = np.sqrt(np.diag(pcov)). How the sigma \n",
        "         parameter affects the estimated covariance depends on absolute_sigma \n",
        "         argument, as described above. If the Jacobian matrix at the solution \n",
        "         doesn’t have a full rank, then ‘lm’ method returns a matrix filled \n",
        "         with np.inf, on the other hand ‘trf’ and ‘dogbox’ methods use \n",
        "         Moore-Penrose pseudoinverse to compute the covariance matrix.\n",
        "\n",
        "\n",
        "Reading through this documentation, we can learn that **popt is an array which**<br> \n",
        "**contains our optimal parameter values** *(popt = parameters-optimal)* and that **pcov**<br> \n",
        "**is a 2-D array where the diagonal values of the array correspond to the**<br> **variance of the parameter estimation**. That means, if we want to get the **error**<br> \n",
        "**for a single paramter**, then the value at **pcov[0][0] will be the variance** for<br> \n",
        "that paramter. Likewise, **if we had two parameters** we were solving for, our<br> \n",
        "parameter **variances would be pcov[0][0] and pcov[1][1]** for our first and second<br> \n",
        "parameters respectively.\n",
        "\n",
        "Knowing our inputs and outputs, we can attempt to use the the fitting function<br> \n",
        "to solve for out two unknown parameters that we generated earlier."
      ],
      "metadata": {
        "id": "OirInKqsIoVT"
      },
      "id": "OirInKqsIoVT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269960ef",
      "metadata": {
        "id": "269960ef"
      },
      "outputs": [],
      "source": [
        "popt, pcov = curve_fit(exponential_function, x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's **unpack our returned values** and compare to the real values we fed into the<br> \n",
        "fitting function. The documentation tells us **popt will contain our parameters**<br> \n",
        "and our **error will be given by perr = np.sqrt(np.diag(pcov))**.\n"
      ],
      "metadata": {
        "id": "ZBzXW-aXJW8e"
      },
      "id": "ZBzXW-aXJW8e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e257aec9",
      "metadata": {
        "id": "e257aec9",
        "outputId": "ea56af4a-85a9-42c8-d8e1-60678b0e5167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real A =  3.839051899607303\n",
            "Real B =  15.05599389316587\n",
            "Fitted A =  3.839051899607303  +/-  0.0\n",
            "Fitted B =  15.05599389316587  +/-  0.0\n"
          ]
        }
      ],
      "source": [
        "print('Real A = ', A[0])\n",
        "print('Real B = ', B[0])\n",
        "print('Fitted A = ', popt[0], ' +/- ', np.sqrt(pcov[0][0]))\n",
        "print('Fitted B = ', popt[1], ' +/- ', np.sqrt(pcov[1][1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our fitted values almost perfectly match our real values that we used earlier."
      ],
      "metadata": {
        "id": "I1ANa0j3Jgeh"
      },
      "id": "I1ANa0j3Jgeh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last thing to consider from the documentation is the **errors** it can raise.<br> \n",
        "For example, consider if your y values didn't have any rational relation to x<br> \n",
        "according to the function provided."
      ],
      "metadata": {
        "id": "L9L3zROBJjv2"
      },
      "id": "L9L3zROBJjv2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5237740b",
      "metadata": {
        "id": "5237740b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0dfdddd-1402-457a-b0ed-d876d230c297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
            "  warnings.warn('Covariance of the parameters could not be estimated',\n"
          ]
        }
      ],
      "source": [
        "bad_y = np.ones(100)\n",
        "popt, pcov = curve_fit(exponential_function, x, bad_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code returns the error **OptimizeWarning** with the description that the<br> \n",
        "**covariance of the parameters could not be estimated**. If we open up the<br> \n",
        "covariance values we can see that **the variance corresponding to A and B is now**<br> \n",
        "**infinite**."
      ],
      "metadata": {
        "id": "gXpg9SgwKA_G"
      },
      "id": "gXpg9SgwKA_G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae34000",
      "metadata": {
        "id": "dae34000",
        "outputId": "9bef2553-aad2-40f1-9cb4-39b4230b3a5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variances:  inf ,  inf\n"
          ]
        }
      ],
      "source": [
        "print('Variances: ', pcov[0][0], ', ', pcov[1][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpreting this error, we know that the **covariance corresponds to the square**<br> \n",
        "**of the error in our parameter fitting**. If those values are infinite, **we might**<br> \n",
        "**have some issue with either our x or y values being completely uncorrelated**,<br> \n",
        "which could cause our uncertainty to blow up."
      ],
      "metadata": {
        "id": "v6NrX2nuKId7"
      },
      "id": "v6NrX2nuKId7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some other things that might cause this sort of error? One more<br> \n",
        "expample is  included below but **notice how the error doesn't get called again**.<br> \n",
        "**Some libraries have a limit on the number of times the same error warning will**<br> \n",
        "**appear in a single instance of your code running**. You can confirm this by<br> \n",
        "rerunning the block that first gave the error warning again. Notice how the<br> \n",
        "error warning disappears."
      ],
      "metadata": {
        "id": "t562c8CoKMu7"
      },
      "id": "t562c8CoKMu7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893c2de9",
      "metadata": {
        "id": "893c2de9",
        "outputId": "884f69a1-55fb-4a9f-9bae-037920999f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variances:  inf ,  inf\n"
          ]
        }
      ],
      "source": [
        "new_bad_y = np.random.uniform(0,10000000000000, size=100)\n",
        "popt, pcov = curve_fit(exponential_function, x, new_bad_y)\n",
        "print('Variances: ', pcov[0][0], ', ', pcov[1][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e635240e",
      "metadata": {
        "id": "e635240e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:.conda-cold590] *",
      "language": "python",
      "name": "conda-env-.conda-cold590-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}