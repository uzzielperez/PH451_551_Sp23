{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UAPH451551/PH451_551_Sp23/blob/main/Exercises/05_neural_nets_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUOwclhJHNDP"
      },
      "source": [
        "# Hands On #5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piBSRAqc96nN"
      },
      "source": [
        "**Chapter 10 – Introduction to Artificial Neural Networks with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFOtkrf3HNDS"
      },
      "source": [
        "Due date: 2023-03-06\n",
        "\n",
        "File name convention: For group 42 and members Richard Stallman and Linus <br> Torvalds it would be: <br>\n",
        "\"05_neural_nets_with_keras_Stallman_Torvalds.pdf\"\n",
        "\n",
        "Submission via blackboard (UA).\n",
        "\n",
        "Feel free to answer free text questions in text cells using markdown and <br>\n",
        "possibly $\\LaTeX{}$ if you want to.\n",
        "\n",
        "**You don't have to understand every line of code here and it is not intended <br> \n",
        "for you to try to understand every line of code.<br>\n",
        "Big blocks of code are usually meant to just be clicked through.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3TTeAuN96nU"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3_Ulmke96nV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKK8dS-C96nW"
      },
      "source": [
        "# Perceptrons\n",
        "\n",
        "**Perceptrons are a form of linear classifier**. The characteristic expression is <br> \n",
        "$\\Sigma_i w_i \\cdot x_i + b$. Where x are your inputs and w are your model\n",
        "weights<br> \n",
        "and b is a learnable bias term. The classification part comes in by setting <br>\n",
        "**any positive result of the above expression as the 1 or True label** and any <br> **negative result as the 0 or False label**. We then use stochastic gradient <br>\n",
        "descent to optimize the weights and bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc419YFJ96nX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
        "y = (iris.target == 0).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tut21LOA-I2r"
      },
      "source": [
        "### Task 1:\n",
        "Fit the iris dataset into a Perceptron layer and predict the class of a sample <br>\n",
        "with petal length of 2 and a petal width of 0.5. \n",
        "\n",
        "Use: \n",
        "`max_iter=1000`, `tol =1e-3` and `random_state= 42`.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2GbE_Wj96nW"
      },
      "source": [
        "**Note**: we set `max_iter` and `tol` explicitly to avoid warnings about the <br>\n",
        "fact that their default value will change in future versions of Scikit-Learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsnymzLuLvm2"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5wg3vIj3gxL"
      },
      "outputs": [],
      "source": [
        "#per_clf = \n",
        "\n",
        "#y_pred = "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU8nJGQo96nY"
      },
      "outputs": [],
      "source": [
        "#y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L33GBuxILvm4"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzqgH5uG96nZ"
      },
      "outputs": [],
      "source": [
        "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
        "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
        "\n",
        "axes = [0, 5, 0, 2]\n",
        "\n",
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
        "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
        "    )\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "y_predict = per_clf.predict(X_new)\n",
        "zz = y_predict.reshape(x0.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
        "\n",
        "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
        "from matplotlib.colors import ListedColormap\n",
        "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
        "\n",
        "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.ylabel(\"Petal width\", fontsize=14)\n",
        "plt.legend(loc=\"lower right\", fontsize=14)\n",
        "plt.axis(axes)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7AzNDaU-xOV"
      },
      "source": [
        "### Task 2\n",
        " Elaborate on the difference between a perceptron and logistic regression.\n",
        "\n",
        " **Hint:** Consider the nature of the boundary in the above plot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW0MVBaoHNDW"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k64m9OUeHNDW"
      },
      "source": [
        "Task 2 answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdoyypmcHNDW"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZr175SP96na"
      },
      "source": [
        "# Activation functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBhSPTlaDZcE"
      },
      "source": [
        "### Task 3\n",
        "Describe the role of activation functions within a neural network. If you build <br>\n",
        "a neural network with no activation function, which model that we've seen in <br>\n",
        "this class would your network resemble?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9pD5KasHNDW"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSarFW4JHNDX"
      },
      "source": [
        "Task 3 answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rETgKA70HNDX"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zZHVAV096nd"
      },
      "source": [
        "# Building an Image Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6d_vhWv96nd"
      },
      "source": [
        "First let's import TensorFlow and Keras. **Tensorflow is a machine learning** <br>\n",
        "**platform** developed by Google Brain. **Keras is a python interface for Tensorflow**. <br>\n",
        "That mean that **we'll typically use model and functions from Keras** but those are <br>\n",
        "built using building blocks and data structures from Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2XiMCMx96nd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSUOusSb96nd"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qClTS5Qo96nd"
      },
      "outputs": [],
      "source": [
        "keras.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IC001Fj96ne"
      },
      "source": [
        "Let's start by loading the [fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset. Keras has a number <br>\n",
        "of functions to load popular datasets in `keras.datasets`. **The dataset is** <br> **already split for you between a training set and a test set**, but it can be <br> useful to split the training set further to have a validation set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1Vd2nar96ne"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm2mJI2v96ne"
      },
      "source": [
        "The training set contains 60,000 grayscale images, each 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKeNURr096nf"
      },
      "outputs": [],
      "source": [
        "X_train_full.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2q7eH1GS96nf"
      },
      "source": [
        "Each pixel intensity is represented as a byte (0 to 255):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpJBj89g96ng"
      },
      "outputs": [],
      "source": [
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up_jreEp96ng"
      },
      "source": [
        "Let's **split the full training set into a validation set and a (smaller)** <br> **training set**. We also **scale the pixel intensities down to the 0-1 range** and <br> \n",
        "convert them to floats, by dividing by 255. This is essentially min-max scaling <br>\n",
        "or normalization for pixels with a maximum value of 255 and a minimum of 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAZzoYRD96ng"
      },
      "outputs": [],
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG-ZXYbM96ng"
      },
      "source": [
        "You can plot an image using Matplotlib's `imshow()` function, with a `'binary'` <br>\n",
        "color map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5qfRYzl96ng"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[0], cmap=\"binary\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HIhKfBK96nh"
      },
      "source": [
        "The labels are the class IDs (represented as uint8), from 0 to 9:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC0hpimX96nh"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuQH9NeY96nh"
      },
      "source": [
        "Here are the corresponding class names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DnDTta596nh"
      },
      "outputs": [],
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z3ctcPE96ni"
      },
      "source": [
        "So the first image in the training set is a coat:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo3nXTyr96ni"
      },
      "outputs": [],
      "source": [
        "class_names[y_train[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVf64Kv96ni"
      },
      "source": [
        "The validation set contains 5,000 images, and the test set contains 10,000 images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3DPLv7496ni"
      },
      "outputs": [],
      "source": [
        "X_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBVt2-n196nj"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr7f-I2i96nj"
      },
      "source": [
        "Let's take a look at a sample of the images in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiwEaciG96nj"
      },
      "outputs": [],
      "source": [
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "        plt.title(class_names[y_train[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1G5vYM4AEYy"
      },
      "source": [
        "**Training a neural network using Keras:** In the cells below we  build an deep <br> \n",
        "neural network model using Keras Sequential tool. The input is an image of <br> shape 28 by 28. We use a network with 2 hidden layers with 300 and 100 neurons, <br> \n",
        "respectively. The 'softmax' output activation function is used for multi-label <br> \n",
        "classification. **This is essentially a multi-layer perceptron model with** <br>\n",
        "**activation functions added** to each \"neuron\". Additionally, **we no longer end** <br>\n",
        "**the model with a decision function** that outputs either a 0 or 1. Here our final <br>\n",
        "layer's **weights will be passed through a softmax function which will output a** <br>\n",
        "**collection of 10 values which add up to 1**. These are the probabilities of each <br>\n",
        "class being the correct class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFYpKULg96nk"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHTrilwL96nk"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(300, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6wLCkUc96nk"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt04f4Ug96nl"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFvLmimPHNDc"
      },
      "source": [
        "We can look at the layers directly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3skG5ULDHNDc"
      },
      "outputs": [],
      "source": [
        "hidden1 = model.layers[1]\n",
        "hidden1.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVQqeMeS96nl"
      },
      "outputs": [],
      "source": [
        "model.get_layer(hidden1.name) is hidden1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR5m6LjX96nl"
      },
      "outputs": [],
      "source": [
        "weights, biases = hidden1.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETO_Mi2f96nm"
      },
      "outputs": [],
      "source": [
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-AWFPWX96nm"
      },
      "outputs": [],
      "source": [
        "weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qb7RJWWg96nm"
      },
      "outputs": [],
      "source": [
        "biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRfITXCA96nm"
      },
      "outputs": [],
      "source": [
        "biases.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDu2dLD8BbeJ"
      },
      "source": [
        "**Compilation:**  \n",
        "**Keras allows us to \"compile\" a complete model which uses the model parameter** <br> \n",
        "**structure we defined above**. We compile the model using the  <br>\n",
        "**\"sparse_categorical_crossentropy\" loss function** and **\"accuracy\" as metric** for a <br> \n",
        "multi-label classification task. In addition, we choose the **\"sgd\" optimizer**.<br>\n",
        "The **SGD optimizer is a derivative of the SGD algorithm** but, instead of updating <br>\n",
        "coefficients for a linear regression as we saw in previous exercises, we <br> **compute the gradient of our loss function** (sparse categorical crossentropy) <br>\n",
        "**with respect to our model weights and layer biases** and use that to **update our** <br>\n",
        "**weights and biases**. Note that our gradient will now be the sum of more <br> complicated partial derivatives. $\\partial L/\\partial w_i = (\\partial L / \\partial f(w_i)) (\\partial f(w_i) / \\partial w_i)$ <br>\n",
        "where $f(w_i) = ReLU(w_i + b)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iha1BNF296nn"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"sgd\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z01D2HtY6B4r"
      },
      "source": [
        "Now let's train the model for 30 epochs.\n",
        "\n",
        "We save the most crucial parameters (`['loss', 'accuracy', 'val_loss',` <br> '`val_accuracy']`) in a dictionary named \"history\". "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niNnbD7U96no"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=30,\n",
        "                    validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZsFB62z96no"
      },
      "outputs": [],
      "source": [
        "history.params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epochs is the number of full passes of your data. Step is the number of <br>\n",
        "times your model will update per epoch. Verbosity is the amount of information <br>\n",
        "that will be included. Verbosity of 0 has minimal information. Verbosity of 1 <br>\n",
        "has the most information. Verbosity of 2 is in between."
      ],
      "metadata": {
        "id": "YRjl0WpRhKzV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdaUfmYb96np"
      },
      "outputs": [],
      "source": [
        "print(history.epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3tukEej96np"
      },
      "outputs": [],
      "source": [
        "history.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the learning curves for this model training."
      ],
      "metadata": {
        "id": "ht9uxLpwhpcR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCv_GPMi96np"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2WdGqAlC0bm"
      },
      "source": [
        "### Task 4\n",
        " Validate your model using `model.evaluate` on the test set made of `X_test` <br> and `y_test`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYn6hY0XHNDf"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfC_sLA_96nq"
      },
      "outputs": [],
      "source": [
        "# evaluate model on  test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPp1YYCOHNDg"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM8ssoN0FjYS"
      },
      "source": [
        "### Task 5\n",
        " Select the first three samples from the test set and predict their <br> corresponding classes using model.predict_classes . Then print the names/ <br>\n",
        " categories of the elements in  question (Eg. \"Pants\", \"trouser\") \n",
        "\n",
        "Hint: With `model.predict(...)` you can get the predictions in a [one-hot-encoded](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) <br> \n",
        "format. Use `np.argmax(prediction, axis=-1)` on the one-hot-encoded predicitons <br>\n",
        "to get the classes numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C0en5Jk96nq"
      },
      "outputs": [],
      "source": [
        "X_new = X_test[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMl_pVJMHNDg"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WoScu8CHNDg"
      },
      "outputs": [],
      "source": [
        "# y_pred = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arO65xXFHNDg"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNkCYEEIHNDg"
      },
      "outputs": [],
      "source": [
        "y_test[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MloueY3o96nr"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7.2, 2.4))\n",
        "for index, image in enumerate(X_new):\n",
        "    plt.subplot(1, 3, index + 1)\n",
        "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
        "    plt.axis('off')\n",
        "    plt.title(class_names[y_test[index]], fontsize=12)\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdQPEnaa96nr"
      },
      "source": [
        "# Regression MLP\n",
        "\n",
        "We can also build multi-layer perceptrons for regression. The difference here <br>\n",
        "is that we remove the step function that says "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMxzRNLS96ns"
      },
      "source": [
        "Let's load, split and scale the [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ3bFpfU96ns"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJiLPiB5Gzht"
      },
      "source": [
        "### Task 6\n",
        " Scale your training, validation, and test feature matrices using scikit-learn's <br>\n",
        "[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Best practice is to fit your scaler to a single sample and <br>\n",
        "scale all samples by the same amount. This standard scaler is implementing <br>\n",
        "standardization also sometimes referred to as standard normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWwom68-HNDh"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0ehUJYh7Dcw"
      },
      "outputs": [],
      "source": [
        "#scaler = \n",
        "#scaler = scaler.fit()\n",
        "#X_train = \n",
        "#X_valid = \n",
        "#X_test = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z4Q-GaqHNDh"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv60cUzR96ns"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NgYV0XyIlfr"
      },
      "source": [
        "### Task 7\n",
        " Build a Neural Network with one hidden layer with 30 neurons. The output layer <br> \n",
        "has one neuron, which is the regression value. Compile, fit then train this <br> \n",
        "network on the data created in task 6 while choosing the suitable loss function <br> \n",
        "and the SGD optimizer. \n",
        "\n",
        "**N.B:**  This task is similar to task 5 except that we now do regression not <br> classification. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M37QSQ8jHNDi"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wj5v_bRU96ns"
      },
      "outputs": [],
      "source": [
        "#model = #\n",
        "\n",
        "\n",
        "#...\n",
        "#history = \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoSs90vjHNDj"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G8ujXkmHNDj"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSADjQQDJLgh"
      },
      "source": [
        "### Task 8\n",
        "Validate your model using `model.evaluate` on the test set. <br>\n",
        "Also predict one element of the test set of your choice (`X_test[42]` for <br> example) and compare to the real value.\n",
        "\n",
        "Note that to have consistent dimensionality, you'll have to pass `X_test[42:43]` <br>\n",
        "rather than `X_test[42]` into your model prediction. Passing only `X_test[42]` <br> in will result in an error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS4iQtpdHNDj"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3IL0WlYJCx6"
      },
      "outputs": [],
      "source": [
        "#mse_test = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7gfM8qzHNDk"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_YAL3g-96nx"
      },
      "source": [
        "# Saving the model weights for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIMTsRwT96ny"
      },
      "outputs": [],
      "source": [
        "model.save(\"my_keras_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrgCYxY596ny"
      },
      "outputs": [],
      "source": [
        "model_reloaded = keras.models.load_model(\"my_keras_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeUU8hqO96ny"
      },
      "outputs": [],
      "source": [
        "model_reloaded.predict(X_test[42:43])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTn29YSI96ny"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"my_keras_weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ebtp4OJ96nz"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"my_keras_weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AcZE0DNHNDl"
      },
      "source": [
        "## Looking at the saved weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwtqRZ1VHNDl"
      },
      "outputs": [],
      "source": [
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsXdJsPmHNDl"
      },
      "outputs": [],
      "source": [
        "f = h5py.File(\"my_keras_weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5Tqf1koHNDl"
      },
      "outputs": [],
      "source": [
        "list(f.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ECPbJi1HNDl"
      },
      "outputs": [],
      "source": [
        "for name in f[\"dense_3/dense_3\"]:\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emA6xl2OHNDl"
      },
      "outputs": [],
      "source": [
        "f[\"dense_3\"][\"dense_3\"].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwJ6ozAeHNDl"
      },
      "outputs": [],
      "source": [
        "np.array(f[\"dense_3\"][\"dense_3\"][\"bias:0\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r--t1BSHHNDl"
      },
      "outputs": [],
      "source": [
        "np.array(f[\"dense_3\"][\"dense_3\"][\"kernel:0\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqDN8nxVHNDm"
      },
      "outputs": [],
      "source": [
        "f[\"dense_3\"][\"dense_3\"][\"kernel:0\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv2O5ZTwHNDm"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIm64h5sHNDm"
      },
      "source": [
        "One layer is actually nothing but performing a matrix multiplication, adding <br> \n",
        "the bias and putting it through the activation function. <br>\n",
        "You can see this by looking at the shape of `dense_3`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2TzmQLLHNDm"
      },
      "source": [
        "### Task 9\n",
        " For `X_train[0]` perform the forward pass yourself using matrix <br> multiplications.\n",
        "Remember to include the biases. <br>\n",
        "Check with the prediction of the model that you get exactly the same! <br>\n",
        "\n",
        "Hints:\n",
        "- use `np.dot(x,y)` for matrix multiplication\n",
        "- for the first layer it would look like this:\n",
        "    * matrix mult: `X_new` dot `l1`\n",
        "    * add bias `b1`\n",
        "    * apply `relu(...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKw_DLg3HNDm"
      },
      "outputs": [],
      "source": [
        "b1 = np.array(f[\"dense_3\"][\"dense_3\"][\"bias:0\"])\n",
        "l1 = np.array(f[\"dense_3\"][\"dense_3\"][\"kernel:0\"])\n",
        "b2 = np.array(f[\"dense_4\"][\"dense_4\"][\"bias:0\"])\n",
        "l2 = np.array(f[\"dense_4\"][\"dense_4\"][\"kernel:0\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a9dRAu9HNDm"
      },
      "outputs": [],
      "source": [
        "X_new = X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n8T3Jp_HNDm"
      },
      "outputs": [],
      "source": [
        "X_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azxpa8UJHNDn"
      },
      "outputs": [],
      "source": [
        "l1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YIy1pfnHNDn"
      },
      "outputs": [],
      "source": [
        "b1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va6L70U_HNDn"
      },
      "outputs": [],
      "source": [
        "def relu(z):\n",
        "    return np.maximum(0, z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2J5yv18SHNDn"
      },
      "outputs": [],
      "source": [
        "model.predict(X_train[0:1])   # reproduce this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cFbtYJrHNDn"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XRFSwoyqkCFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPTqjAdiHNDn"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EFNcwqg96n9"
      },
      "source": [
        "# Optional task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cO1eZvL96n-"
      },
      "source": [
        "**Exercise (bonus task, +3 points):**   \n",
        "Train a deep MLP on the MNIST dataset (you can load it using <br>\n",
        "`keras.datasets.mnist.load_data()`. See if you can get over 98% precision.\n",
        "\n",
        "You can try searching for the optimal learning rate by using the approach <br>\n",
        "presented in this chapter (i.e., by growing the learning rate exponentially, <br> \n",
        "plotting the loss, and finding the point where the loss shoots up). Try adding <br> \n",
        "all the bells and whistles—save checkpoints, use early stopping, and plot <br> learning curves using TensorBoard. <br>\n",
        "Feel free to use other methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRSB5E6q96n-"
      },
      "source": [
        "Let's load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZxFNmxd96n-"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFbDQB_e96n-"
      },
      "source": [
        "Just like for the Fashion MNIST dataset, the MNIST training set contains 60,000 <br> \n",
        "grayscale images, each 28x28 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKu9ctYq96n-"
      },
      "outputs": [],
      "source": [
        "X_train_full.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjAPFHCy96n_"
      },
      "source": [
        "Each pixel intensity is also represented as a byte (0 to 255):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKsd4QsX96n_"
      },
      "outputs": [],
      "source": [
        "X_train_full.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkMt_Ore96n_"
      },
      "source": [
        "Let's split the full training set into a validation set and a (smaller) <br>\n",
        "training set. We also scale the pixel intensities down to the 0-1 range and <br> \n",
        "convert them to floats, by dividing by 255, just like we did for Fashion MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGsM7Im596n_"
      },
      "outputs": [],
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7xyLzpCHNDp"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4YQCb5yHNDp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohc_encoder = OneHotEncoder()\n",
        "ohc_encoder.fit(y_train.reshape(-1,1))\n",
        "y_train_ohc = ohc_encoder.transform(y_train.reshape(-1,1))\n",
        "y_valid_ohc = ohc_encoder.transform(y_valid.reshape(-1,1))\n",
        "y_test_ohc = ohc_encoder.transform(y_test.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAZyUbSEHNDp"
      },
      "outputs": [],
      "source": [
        "y_train_ohc.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJIP6oa1HNDp"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd4HvnoeHNDq"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSb2rD9yHNDq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMfLw_SjHNDq"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "nav_menu": {
      "height": "264px",
      "width": "369px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}