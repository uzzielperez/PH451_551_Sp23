{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UAPH451551/PH451_551_Sp23/blob/main/Exercises/08A_autoencoders_and_gans.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0234KzN5W_Yr"
      },
      "source": [
        "# Hands On #8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u409K-vLW_Yt"
      },
      "source": [
        "**Chapter 17 – Autoencoders and GANs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_5rT9hCW_Yu"
      },
      "source": [
        "Due date: 2023-04-07\n",
        "\n",
        "File name convention: For group 42 and memebers Richard Stallman and Linus <br>\n",
        "Torvalds it would be <br>\n",
        "\"08_Exercise8_group42_Stallman_Torvalds.pdf\".\n",
        "\n",
        "Submission via blackboard (UA).\n",
        "\n",
        "Feel free to answer free text questions in text cells using markdown and <br>\n",
        "possibly $\\LaTeX{}$ if you want to.\n",
        "\n",
        "**You don't have to understand every line of code here and it is not intended <br> \n",
        "for you to try to understand every line of code.   <br>\n",
        "Big blocks of code are usually meant to just be clicked through.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nBVIiFCW_Yv"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z7QD-rNW_Yv"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMItxgFSW_Yw"
      },
      "source": [
        "A couple utility functions to plot grayscale 28x28 image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm5m1yefW_Yw"
      },
      "outputs": [],
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"binary\")\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R29YO-K-W_Yw"
      },
      "source": [
        "# Simple linear Autoencoder (=PCA)\n",
        "\n",
        "Autoencoders are form of **unsupervised learning** algorithm that attempt to encode <br>\n",
        "or **transform** an input into some sort of (typically **lower-dimensional**) space <br>\n",
        "where it has different values and then decode the encoded data back to its <br>\n",
        "**original state**. A consequence of this approach is that your model learns the <br>\n",
        "**characteristic behavior** of your data set. Once trained, autoencoders can do <br>\n",
        "everything from **detect anomalies** and outliers in unseen data to **adding or** even <br>\n",
        "**removing noise** from new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cLWKPG6W_Yx"
      },
      "source": [
        "Build 3D dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzyx9W8AW_Yx"
      },
      "outputs": [],
      "source": [
        "np.random.seed(4)\n",
        "\n",
        "def generate_3d_data(m, w1=0.1, w2=0.3, noise=0.1):\n",
        "    \"\"\"create some 3d data with noise\"\"\"\n",
        "    angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "    data = np.empty((m, 3))\n",
        "    data[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
        "    data[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
        "    data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n",
        "    return data\n",
        "\n",
        "X_train = generate_3d_data(1000)\n",
        "X_train = X_train - X_train.mean(axis=0, keepdims=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfM-z47EW_Yx"
      },
      "outputs": [],
      "source": [
        "ax = plt.axes(projection=\"3d\")\n",
        "ax.scatter3D(X_train[:,0], X_train[:,1], X_train[:,2], c=X_train[:,2], cmap=\"viridis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbRI2sf0W_Yx"
      },
      "source": [
        "Let's try to \"compress\" the data using an autoencoder.\n",
        "\n",
        "As a sidenote: Compression is tightly linked to intelligence and there are even arguments\n",
        "that compression might be all there is to intelligence.   \n",
        "If you are interested in this topic you can read about the [Hutter prize](http://prize.hutter1.net/hrules.htm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoxoebi3W_Yx"
      },
      "source": [
        "Now let's build the Autoencoder..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG0df7Z3W_Yy"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# encoder: from 3 to 2 dimensions\n",
        "encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
        "# decoder: from 2 to 3 dimensions\n",
        "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqjQM9F1W_Yy"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(encoder, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d_T0vuQW_Yy"
      },
      "outputs": [],
      "source": [
        "keras.utils.plot_model(decoder, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH-fJHoLW_Yy"
      },
      "source": [
        "## Task 1: \n",
        "If you don't understand autoencoders, we strongly recommend reading the parts <br>\n",
        "in the book (Chapter 17) first.\n",
        "\n",
        "a) Build an autoencoder model with the two subcomponents: the encoder and the <br> \n",
        "decoder. All you have to do is to \"stack\" the encoder and decoder, `[encoder,` <br> `decoder]` in a `keras.models.Sequential`.  <br> \n",
        "b) Compile the model with `mse` loss and SGD optimizer with `lr=1`.   <br>\n",
        "c) Train the model (20 epochs) on the dataset created above. Think about what <br>\n",
        "`X` and `y` need to be for training the autoencoder. Remember that you want to <br> \n",
        "reconstruct the input with an autoencoder.<br>\n",
        "d) Encode the dataset using only the trained encoder. The `encoder` will be <br>\n",
        "mutated by the autoencoder training, so you can just use it to do this step <br> \n",
        "because it is already trained. Call the output `codings` for the plotting code <br> \n",
        "below.<br>\n",
        "e) Look at the plot of the encodings and explain the purpose of this <br> encoder. <br>\n",
        "f) Decode the encodings again and plot them in 3D using the same code as above <br> \n",
        "when we plot `X_train`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsnymzLuLvm2"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rcrUlWKsZucc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L33GBuxILvm4"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfzdwhoRW_Yz"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(4,3))\n",
        "plt.plot(codings[:,0], codings[:, 1], \"b.\")\n",
        "plt.xlabel(\"$z_1$\", fontsize=18)\n",
        "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTyuFXyEW_Yz"
      },
      "source": [
        "# Autoencoder for MNIST\n",
        "Let's use the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Zf5LOgW_Yz"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9SZ-YQoW_Yz"
      },
      "source": [
        "Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6TqlRqWW_Yz"
      },
      "outputs": [],
      "source": [
        "encoder2 = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(30, activation=\"selu\"),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzHB9kLjW_Y0"
      },
      "source": [
        "## Task 2: \n",
        "a) Above the code for the encoder is given. Build the corresponding decoder <br> \n",
        "(`decoder2`). The last layer of the decoder will have to be `keras.layers.` <br> \n",
        "`Reshape([28, 28])`. Just like in task 1, build `autoencoder2` from `encoder2` <br> \n",
        "and `decoder`.<br>\n",
        "b) Compile the model using loss: `tf.keras.losses.BinaryCrossentropy(from_logits=True)`, <br>\n",
        "SGD optimizer with `lr=1.0`, and `accuracy` as metrics.<br>\n",
        "c) Train the model using `X_train` (10 epochs) as both the inputs and the <br> targets (and similarly, use `X_valid` as both the validation inputs and targets). <br>\n",
        "d) Using the function `show_reconstructions` below, look at the reconstructions <br> \n",
        "and comment on them.<br>\n",
        "e) Run these 2 commands:<br>\n",
        "`X_train[0].shape` and  `encoder2.predict(X_train[0:1])[0].shape` and explain<br> \n",
        "their outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bde7eOP4W_Y0"
      },
      "outputs": [],
      "source": [
        "def show_reconstructions(model, images=X_valid, n_images=5):\n",
        "    reconstructions = model.predict(images[:n_images])\n",
        "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
        "    for image_index in range(n_images):\n",
        "        plt.subplot(2, n_images, 1 + image_index)\n",
        "        plot_image(images[image_index])\n",
        "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
        "        plot_image(reconstructions[image_index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWHr9I8qW_Y0"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "obr7HcfZZvxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAOmhtneW_Y0"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE3vvgMqW_Y0"
      },
      "source": [
        "### \"Looking\" at the encoding\n",
        "Here we wil in some sense \"look\" at the encoding. <br>\n",
        "We will use TSNE to transform the encoding to 2D and then plot in a 2D plane.<br>\n",
        "\n",
        "No questions to anwer here, just look at the plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzZzCis_W_Y0"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "X_valid_compressed = encoder2.predict(X_valid)\n",
        "tsne = TSNE()\n",
        "X_valid_2D = tsne.fit_transform(X_valid_compressed)\n",
        "X_valid_2D = (X_valid_2D - X_valid_2D.min()) / (X_valid_2D.max() - X_valid_2D.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdI_QtHUW_Y1"
      },
      "outputs": [],
      "source": [
        "# adapted from https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
        "plt.figure(figsize=(10, 8))\n",
        "cmap = plt.cm.tab10\n",
        "plt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=cmap)\n",
        "image_positions = np.array([[1., 1.]])\n",
        "for index, position in enumerate(X_valid_2D):\n",
        "    dist = np.sum((position - image_positions) ** 2, axis=1)\n",
        "    if np.min(dist) > 0.02: # if far enough from other images\n",
        "        image_positions = np.r_[image_positions, [position]]\n",
        "        imagebox = mpl.offsetbox.AnnotationBbox(\n",
        "            mpl.offsetbox.OffsetImage(X_valid[index], cmap=\"binary\"),\n",
        "            position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n",
        "        plt.gca().add_artist(imagebox)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwgpuuBrW_Y1"
      },
      "source": [
        "## Using Convolutional Layers Instead of Dense Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRGqyepHW_Y1"
      },
      "source": [
        "Let's build a stacked Autoencoder with 3 hidden layers and 1 output layer (i.e., 2 stacked Autoencoders)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdO-hSevW_Y1"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "conv_encoder = keras.models.Sequential([\n",
        "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
        "    keras.layers.Conv2D(16, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2)\n",
        "])\n",
        "conv_decoder = keras.models.Sequential([\n",
        "    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"VALID\", \n",
        "                                 activation=\"selu\",\n",
        "                                 input_shape=[3, 3, 64]),\n",
        "    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"SAME\", \n",
        "                                 activation=\"selu\"),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"SAME\", \n",
        "                                 activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huSU_V4PW_Y1"
      },
      "outputs": [],
      "source": [
        "conv_encoder.summary()\n",
        "conv_decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtO0fkmFW_Y1"
      },
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "# depending on your installation you might have to run `pip install visualkeras` (in a separate cell)\n",
        "visualkeras.layered_view(conv_encoder, legend=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAYsWSRhW_Y2"
      },
      "source": [
        "Above is a visual representation of the encoder. Alas visualkeras does not <br>\n",
        "support `Conv2DTranspose` so we cannot plot the decoder here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lekkehZEW_Y2"
      },
      "source": [
        "### Task 3:\n",
        "a) Build an autoencoder model with the two subcomponents: the convolutional <br> \n",
        "encoder and the convolutional decoder.<br>\n",
        "b) Compile the model using binary cross entropy,  SGD optimizer with lr=1.0 and <br> \n",
        "`[accuracy]` as metrics.<br>\n",
        "c) Train the model using X_train (10 epochs) as both the inputs and the targets <br> \n",
        "(and similarly, use X_valid as both the validation inputs and targets).<br>\n",
        "d) Is the CNN autoencoder better than dense layer's autoencoders? Why?<br>\n",
        "e) What is the shape/size of the input and what is the shape/size of the<br>\n",
        "encoding? Compare to the autoencoder above. (This is similar to task 2e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CwNQtjPW_Y2"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "auSbNXYlZ-Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPY99cNJW_Y2"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSsD3rUzW_Y2"
      },
      "outputs": [],
      "source": [
        "show_reconstructions(conv_ae)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sod574_wW_Y2"
      },
      "source": [
        "# Denoising Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HeIljQuW_Y2"
      },
      "source": [
        "Below we have a similar autoencoder as before, but with an extra <br> `GaussianNoise` layer directly after the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRcb1PS8W_Y2"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "denoising_encoder = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.GaussianNoise(0.2),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(30, activation=\"selu\")\n",
        "])\n",
        "denoising_decoder = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXbFNHO5W_Y3"
      },
      "source": [
        "### Task 4:\n",
        "a) Build an autoencoder model with the two subcomponents: the encoder and the <br> \n",
        "decoder.<br>\n",
        "b) Compile the model using binary cross entropy,  SGD optimizer with lr=1.0 and <br> \n",
        "`accuracy` as metrics.<br>\n",
        "c) Train the model using X_train (10 epochs) as both the inputs and the targets <br> \n",
        "(and similarly, use X_valid as both the validation inputs and targets).<br>\n",
        "d) Explain why adding Gaussian noise to the input would help the autoencoder to <br> \n",
        "learn.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfvpHN08W_Y3"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaJu8WFLW_Y3"
      },
      "outputs": [],
      "source": [
        "#denoising_ae = \n",
        "#denoising_ae.compile(...)\n",
        "#history = "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYshb9abW_Y3"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X6BRXyraUnc"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4d) answer:"
      ],
      "metadata": {
        "id": "KUcpzlzCaV_B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPI-DZQkaQDn"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9zZ51PUW_Y4"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = keras.layers.GaussianNoise(0.2)\n",
        "show_reconstructions(denoising_ae, noise(X_valid, training=True))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq2L96DpW_Y4"
      },
      "outputs": [],
      "source": [
        "show_reconstructions(denoising_ae, X_valid)   # denoising autoencoder applied to \"sharp\" images\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KeFteGGW_Y4"
      },
      "outputs": [],
      "source": [
        "show_reconstructions(autoencoder2, X_valid)   # original autoencoder without Gaussian noise\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXnhcxTxW_Y4"
      },
      "source": [
        "# Variational Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkmW9Zb9W_Y4"
      },
      "source": [
        "### Task 5:\n",
        "Below you see the implementation of a variational autoencoder.   \n",
        "\n",
        "a) Explain how a variational autoencoder works. What are the differences to a<br>\n",
        "normal autoencoder? <br>\n",
        "b) Explain how you would \"generate\" new data with a variational autoencoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06-8_OFW_Y4"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TcxIddFW_Y4"
      },
      "source": [
        "Task 5a) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvfmTHoCW_Y4"
      },
      "source": [
        "Task 5b) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aU2NupCW_Y5"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WKYsVhoW_Y5"
      },
      "outputs": [],
      "source": [
        "K = keras.backend\n",
        "kl_divergence = keras.losses.kullback_leibler_divergence\n",
        "\n",
        "class KLDivergenceRegularizer(keras.regularizers.Regularizer):\n",
        "    def __init__(self, weight, target=0.1):\n",
        "        self.weight = weight\n",
        "        self.target = target\n",
        "    def __call__(self, inputs):\n",
        "        mean_activities = K.mean(inputs, axis=0)\n",
        "        return self.weight * (\n",
        "            kl_divergence(self.target, mean_activities) +\n",
        "            kl_divergence(1. - self.target, 1. - mean_activities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmlB4T9KW_Y7"
      },
      "outputs": [],
      "source": [
        "class Sampling(keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mean, log_var = inputs\n",
        "        return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4d2ad4RW_Y7"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "codings_size = 10\n",
        "\n",
        "inputs = keras.layers.Input(shape=[28, 28])\n",
        "z = keras.layers.Flatten()(inputs)\n",
        "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
        "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
        "codings_mean = keras.layers.Dense(codings_size)(z)\n",
        "codings_log_var = keras.layers.Dense(codings_size)(z)\n",
        "codings = Sampling()([codings_mean, codings_log_var])\n",
        "variational_encoder = keras.models.Model(\n",
        "    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
        "\n",
        "decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
        "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
        "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
        "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
        "outputs = keras.layers.Reshape([28, 28])(x)\n",
        "variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
        "\n",
        "_, _, codings = variational_encoder(inputs)\n",
        "reconstructions = variational_decoder(codings)\n",
        "variational_ae = keras.models.Model(inputs=[inputs], outputs=[reconstructions])\n",
        "\n",
        "latent_loss = -0.5 * K.sum(\n",
        "    1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
        "    axis=-1)\n",
        "variational_ae.add_loss(K.mean(latent_loss) / 784.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA76IELqW_Y7"
      },
      "outputs": [],
      "source": [
        "variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "history = variational_ae.fit(X_train, X_train, epochs=25, \n",
        "                             validation_data=(X_valid, X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Q8D8-xNXW_Y7"
      },
      "outputs": [],
      "source": [
        "show_reconstructions(variational_ae)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMCGS8ZJW_Y8"
      },
      "source": [
        "## Generate Fashion Images\n",
        "Now that we have a variational autoencoder, we can use it to generate fashion <br> \n",
        "images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFioQhixW_Y8"
      },
      "outputs": [],
      "source": [
        "def plot_multiple_images(images, n_cols=None):\n",
        "    n_cols = n_cols or len(images)\n",
        "    n_rows = (len(images) - 1) // n_cols + 1\n",
        "    if images.shape[-1] == 1:\n",
        "        images = np.squeeze(images, axis=-1)\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    for index, image in enumerate(images):\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngYgZ3xKW_Y8"
      },
      "source": [
        "Let's generate a few random codings, decode them and plot the resulting images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-FUu8b4W_Y8"
      },
      "source": [
        "### Task 6:\n",
        "a) Take the encoding of the first image `X_train[0:1]` and add multiples (-10 <br> \n",
        "to 10) of `np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])`. Decode and plot using <br> \n",
        "`plot_multiple_images()`. Hint: The output of `variational_encoder` is  <br>`[codings_mean, codings_log_var, codings]` and you only need the codings, not <br>\n",
        "the mean and var. <br>\n",
        "b) Generate few (e.g. 12) random codings using for example [tf.random.normal](https://www.tensorflow.org/api_docs/python/tf/random/normal). <br>\n",
        "Decode them and plot the resulting images using `plot_multiple_images(images, 4)`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx_KjiaBW_Y8"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your code goes below"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vPx1P1dNa9Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w68oxFi3W_Y8"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your code goes above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "705Eee36W_Y8"
      },
      "source": [
        "Now let's perform semantic interpolation between these images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5B_qgEcW_Y9"
      },
      "source": [
        "# Generative Adversarial Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkZaaKwEW_Y9"
      },
      "source": [
        "### Task 7:\n",
        "Look at the GAN implementation below.   \n",
        "a) Explain what a Generative Adversarial Network does.   \n",
        "b) Run the code below. During every epoch it plots a few images. Comment on the <br> \n",
        "\"progress\" from epoch 1 to 50. <br>\n",
        "The training takes a very long time, you can also simply go to [this link](https://github.com/ageron/handson-ml2/blob/master/17_autoencoders_and_gans.ipynb) <br> \n",
        "and look at the output under the section \"Generative Adversarial Networks\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfmWLs1HW_Y9"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSU6rE64W_Y9"
      },
      "source": [
        "Task 7 a) answer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89CL1qxWW_Y9"
      },
      "source": [
        "Task 7b) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T84dcb-W_Y9"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoeS_lkkW_Y9"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "codings_size = 30\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm6lPrK7W_Y9"
      },
      "outputs": [],
      "source": [
        "gan = keras.models.Sequential([generator, discriminator])\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBh6ydotW_Y9"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wBazV3nW_Y-"
      },
      "outputs": [],
      "source": [
        "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
        "    generator, discriminator = gan.layers\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
        "        for X_batch in dataset:\n",
        "            # phase 1 - training the discriminator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            generated_images = generator(noise)\n",
        "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "            discriminator.trainable = True\n",
        "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "            # phase 2 - training the generator\n",
        "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "            y2 = tf.constant([[1.]] * batch_size)\n",
        "            discriminator.trainable = False\n",
        "            gan.train_on_batch(noise, y2)\n",
        "        plot_multiple_images(generated_images, 8)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx6uDL5aW_Y-"
      },
      "outputs": [],
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size, n_epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fGXZf-WW_Y-"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator(noise)\n",
        "plot_multiple_images(generated_images, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCGqwqTSW_Y-"
      },
      "outputs": [],
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96UNVYGGW_Y-"
      },
      "source": [
        "# Deep Convolutional GAN\n",
        "This is the convolutional variant of the GAN. Again, you can simply look at the <br> \n",
        "ouptut from the [link](https://github.com/ageron/handson-ml2/blob/master/17_autoencoders_and_gans.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj1cy-I7W_Y-"
      },
      "source": [
        "### Task 8:\n",
        "a) Comment on the training progress of the Deep Convolutional GAN.   \n",
        "b) Compare the results from the Deep Convolutional GAN with the results from <br> \n",
        "task 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5_UMYAzW_Y-"
      },
      "source": [
        "↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ your answer goes below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuYe-Iu9W_Y_"
      },
      "source": [
        "Task 8 a) answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B6vdyS6W_Y_"
      },
      "source": [
        "Task 8b) answer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKeBIkkVW_Y_"
      },
      "source": [
        "↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑↑ your answer goes above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRSvHQzSW_Y_"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "codings_size = 100\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n",
        "    keras.layers.Reshape([7, 7, 128]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                                 activation=\"selu\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                                 activation=\"tanh\"),\n",
        "])\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2),\n",
        "                        input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
        "                        activation=keras.layers.LeakyReLU(0.2)),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "gan = keras.models.Sequential([generator, discriminator])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcQODLCYW_Y_"
      },
      "outputs": [],
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JujT_ulxW_Y_"
      },
      "outputs": [],
      "source": [
        "X_train_dcgan = X_train.reshape(-1, 28, 28, 1) * 2. - 1. # reshape and rescale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alKnt_OqW_Y_"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train_dcgan)\n",
        "dataset = dataset.shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwYZss2EW_Y_"
      },
      "outputs": [],
      "source": [
        "train_gan(gan, dataset, batch_size, codings_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kYFduryW_ZA"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "generated_images = generator(noise)\n",
        "plot_multiple_images(generated_images, 8)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "nav_menu": {
      "height": "381px",
      "width": "453px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}